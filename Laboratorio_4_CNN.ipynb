{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 4 - Aprendizaje profundo para la clasificación de imágenes\n",
    "\n",
    "### Roberto Castillo\n",
    "### Juan Lorthiois\n",
    "\n",
    "Siga las instrucciones en negritas para completar el laboratorio.\n",
    "\n",
    "------------\n",
    "\n",
    "## El reto\n",
    "\n",
    "**Su tarea es la de construir un clasificador de imágenes usando Keras (Tensorflow) y Redes Neuronales Convolucionales (CNN) para un conjunto de datos conocido como \"Fashion MNIST dataset\"\"\n",
    ". Este conjunto de datos incluye 10 etiquetas de diferentes tipos de ropa con imágenes de 28 by 28 *escalagris*. Hay un conjunto de datos de entrenamiento de 60,000 imágenes y un conjunto de datos de prueba de 10,000 imágenes.**\n",
    "\n",
    "    Etiqueta\tDescripción\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los datos\n",
    "\n",
    "**Tarea 1: Ejecute el siguiente código para descargar los datos usando Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_entreno, y_entreno), (X_prueba, y_prueba) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los Datos\n",
    "\n",
    "**TAREA 2: Utilice matplotlib para visualizar una imagen del conjunto de datos.  Puede ser cualquier imagen del conjunto de datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = random.randint(0, 69000)\n",
    "image = X_entreno[sample]\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los Datos\n",
    "\n",
    "**TAREA 3: Normalice los datos X entreno y X prueba dividiendo por el valor máximo de los arreglos de las imágenes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(X_entreno.max())\n",
    "print(X_prueba.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entreno= X_entreno / 255\n",
    "X_prueba= X_prueba /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_entreno.max())\n",
    "print(X_prueba.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TAREA 4: Cambie el formato de los arreglos X para que incluyan una 4rta dimensión del canal de color. Similar a lo que se hizo en clase para el conjunto de datos MNIST de números.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_entreno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entreno = X_entreno.reshape(60000, 28, 28, 1)\n",
    "X_prueba = X_prueba.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TAREA 5: Convierta los valores de y_entreno y y_prueba para que estén \"one-hot encoded\" para poder hacer un análisis categórico con Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_entreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_categorica_entreno = to_categorical(y_entreno)\n",
    "y_categorica_prueba = to_categorical(y_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración del Modelo\n",
    "\n",
    "**TAREA 6: Utilice Keras para crear un modelo que contenga, al menos, las siguientes capas (pero siéntase en libertad de experimentar):**\n",
    "\n",
    "* Capa \"2D Convolutional\", filtros = 32 y tamaño_kernel = (4, 4)\n",
    "* Capa de \"Pooling\"\"\n",
    " de tamaño = (2, 2)\n",
    "\n",
    "* Capa de Aplanado\n",
    "* Capa Densa (128 unidades, pero siéntase en libertad de \"jugar\"con este valor), activación RELU\n",
    "\n",
    "* Una capa Final Densa de 10 unidades con activación softmax\n",
    "\n",
    "**Luego compile el modelo con estos parámetros: loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo\n",
    "**TAREA 6: Entrene/Ajuste el modelo con el conjunto X_entreno set. La cantidad de épocas le queda a Ud determinar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1802 - acc: 0.9365\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1679 - acc: 0.9395\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1579 - acc: 0.9439\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1502 - acc: 0.9469\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1427 - acc: 0.9496\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1397 - acc: 0.9523\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1312 - acc: 0.9551\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1274 - acc: 0.9559\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1238 - acc: 0.9582\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1201 - acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c18a60e400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del Modelo\n",
    "\n",
    "**TAREA 7: Muestre los valores de [accuracy, precision, recall, f1-score] que logró el modelo con el conjunto de datos X_prueba data set. Tenga en mente que hay múltiples formas de hacer esto.  Sin embargo, le recomendamos que utilice el mismo procedimiento usado mencionado en la parte de intuición, en clase.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.88      0.83      0.85      1000\n",
      "          3       0.91      0.91      0.91      1000\n",
      "          4       0.83      0.88      0.85      1000\n",
      "          5       0.97      0.98      0.98      1000\n",
      "          6       0.73      0.76      0.74      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.98      0.94      0.96      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gran trabajo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
